import os
import io
import shutil
import asyncio
import logging
import time
import json
import uuid
import signal
import sys
from typing import List, Optional, Dict, Any
from contextlib import asynccontextmanager
from threading import Lock

from pydantic import BaseModel, Field

from dotenv import load_dotenv

import networkx as nx
import matplotlib.pyplot as plt
from fastapi import FastAPI, UploadFile, File, HTTPException, Query, Body, Request, Depends, BackgroundTasks, Form
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from fastapi.middleware.cors import CORSMiddleware

from lightrag import LightRAG, QueryParam
from lightrag.llm.openai import gpt_4o_mini_complete, openai_embed
from lightrag.kg.shared_storage import initialize_pipeline_status

from openai import OpenAI, AuthenticationError, RateLimitError, APIError
from utils.utils_async import process_uploaded_documents, process_webpage_background, process_image_background, process_query_background, process_youtube_background
from utils.db_async import (init_db, fetch_task_result, create_study_topic, get_study_topic, 
                           list_study_topics, update_study_topic, delete_study_topic,
                           create_content_item, get_content_item, list_content_items_by_topic, 
                           get_content_items_count_by_topic, delete_content_item)
from youtube_service import get_youtube_transcript, batch_youtube_transcripts, BatchRequest

# Handle multiple tasks statuses
TASK_STATUS = {}  # Ex: {task_id: "processing" | "done" | "failed"}
TASK_LOCK = Lock()

# Global shutdown flag
SHUTDOWN_EVENT = asyncio.Event()
BACKGROUND_TASKS = set()  # Track running background tasks

# === Configs and Paths ===
# Load environment variables from config.env or .env
load_dotenv("config.env")
load_dotenv()  # Also load from .env if it exists

UPLOAD_DIR = os.getenv("UPLOAD_DIR", "./uploaded_docs")
RAG_DIR = os.getenv("RAG_DIR", "./rag_storage")
GRAPHML_FILENAME = os.getenv("GRAPHML_FILENAME", "graph_chunk_entity_relation.graphml")
GRAPHML_PATH = os.path.join(RAG_DIR, GRAPHML_FILENAME)

os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(RAG_DIR, exist_ok=True)

# === Logging ===
logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(name)s %(message)s')
logger = logging.getLogger("ingest_kgraph")

# === Pydantic Models ===
class StudyTopicCreate(BaseModel):
    name: str = Field(..., min_length=1, max_length=200, description="Name of the study topic")
    description: Optional[str] = Field(None, max_length=1000, description="Description of the study topic")
    use_knowledge_graph: bool = Field(True, description="Whether to use knowledge graph for this topic")

class StudyTopicResponse(BaseModel):
    topic_id: str
    name: str
    description: Optional[str]
    use_knowledge_graph: bool
    created_at: str
    updated_at: str

class StudyTopicUpdate(BaseModel):
    name: Optional[str] = Field(None, min_length=1, max_length=200, description="Name of the study topic")
    description: Optional[str] = Field(None, max_length=1000, description="Description of the study topic")
    use_knowledge_graph: Optional[bool] = Field(None, description="Whether to use knowledge graph for this topic")

# === OpenAI Key Check (Moved to lifespan for graceful failure) ===
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

async def validate_openai_api_key(api_key: str) -> bool:
    """Validate OpenAI API key by making a test call"""
    try:
        test_client = OpenAI(api_key=api_key)
        # Make a simple API call to validate the key
        await asyncio.to_thread(
            test_client.models.list
        )
        return True
    except Exception as e:
        logger.error(f"‚ùå OpenAI API key validation failed: {str(e)}")
        if "401" in str(e) or "invalid_api_key" in str(e):
            logger.error("The provided API key is invalid or expired.")
            logger.error("Please check your API key at: https://platform.openai.com/account/api-keys")
        elif "429" in str(e):
            logger.warning("‚ö†Ô∏è Rate limit reached, but API key appears valid.")
            return True  # Key is valid, just rate limited
        else:
            logger.error("Network or other error during API key validation.")
        return False

def handle_openai_error(e: Exception) -> HTTPException:
    """Convert OpenAI errors to appropriate HTTP exceptions"""
    if isinstance(e, AuthenticationError):
        logger.error(f"OpenAI authentication error: {str(e)}")
        return HTTPException(
            status_code=401, 
            detail={
                "error": "OpenAI authentication failed",
                "message": "Invalid or missing API key. Please check your OPENAI_API_KEY environment variable.",
                "type": "authentication_error"
            }
        )
    elif isinstance(e, RateLimitError):
        logger.warning(f"OpenAI rate limit error: {str(e)}")
        return HTTPException(
            status_code=429,
            detail={
                "error": "OpenAI rate limit exceeded",
                "message": "Please try again later or upgrade your OpenAI plan.",
                "type": "rate_limit_error"
            }
        )
    elif isinstance(e, APIError):
        logger.error(f"OpenAI API error: {str(e)}")
        return HTTPException(
            status_code=502,
            detail={
                "error": "OpenAI API error",
                "message": f"OpenAI service error: {str(e)}",
                "type": "api_error"
            }
        )
    else:
        logger.error(f"Unexpected error: {str(e)}")
        return HTTPException(
            status_code=500,
            detail={
                "error": "Internal server error",
                "message": str(e),
                "type": "unexpected_error"
            }
        )

# === Signal Handlers ===
def signal_handler(signum, frame):
    """Handle shutdown signals gracefully"""
    logger.info(f"üõë Received signal {signum}, initiating graceful shutdown...")
    SHUTDOWN_EVENT.set()

# Register signal handlers
signal.signal(signal.SIGINT, signal_handler)  # Ctrl+C
signal.signal(signal.SIGTERM, signal_handler)  # Docker/Kubernetes shutdown

# === FastAPI Initialization with Lifespan ===
@asynccontextmanager
async def lifespan(app: FastAPI):
    # Startup
    logger.info("üöÄ Starting Study4Me backend server...")
    
    logger.info("üìä Initializing database...")
    await init_db()
    logger.info("‚úÖ Database initialized.")
    
    logger.info("üîë Validating OpenAI API key...")
    
    # Check if API key is set
    if not OPENAI_API_KEY:
        logger.error("‚ùå OPENAI_API_KEY environment variable is not set!")
        logger.error("Please set your OpenAI API key:")
        logger.error("  1. Create a .env file in the backend directory")
        logger.error("  2. Add: OPENAI_API_KEY=your_actual_api_key_here")
        logger.error("  3. Get your API key from: https://platform.openai.com/account/api-keys")
        logger.error("üõë Server startup aborted. Set your API key and restart.")
        raise RuntimeError("OPENAI_API_KEY environment variable must be set. Check logs for setup instructions.")
    
    # Check if API key is a placeholder
    if OPENAI_API_KEY in ["your_openai_api_key_here", "your_actual_api_key_here", "test-key-for-import-check"]:
        logger.error("‚ùå OPENAI_API_KEY is set to a placeholder value!")
        logger.error("Please set your actual OpenAI API key:")
        logger.error("  1. Get your API key from: https://platform.openai.com/account/api-keys")
        logger.error("  2. Update your .env file with: OPENAI_API_KEY=your_actual_api_key_here")
        logger.error("üõë Server startup aborted. Set a real API key and restart.")
        raise RuntimeError("OPENAI_API_KEY must be set to your actual OpenAI API key, not a placeholder.")
    
    # Validate API key with OpenAI
    is_valid = await validate_openai_api_key(OPENAI_API_KEY)
    if not is_valid:
        logger.error("‚ùå Cannot start server with invalid OpenAI API key!")
        logger.error("Please check your API key and restart the server.")
        logger.error("üõë Server startup aborted. Set a valid API key and restart.")
        raise RuntimeError("Invalid OpenAI API key. Server startup aborted.")
    logger.info("‚úÖ OpenAI API key validated successfully.")
    
    logger.info("üß† Initializing LightRAG...")
    rag = None
    try:
        rag = LightRAG(
            working_dir=RAG_DIR,
            embedding_func=openai_embed,
            llm_model_func=gpt_4o_mini_complete,
        )
        await rag.initialize_storages()
        await initialize_pipeline_status()
        app.state.rag = rag
        logger.info("‚úÖ LightRAG initialized successfully.")
    except Exception as e:
        logger.error(f"‚ùå Failed to initialize LightRAG: {str(e)}")
        raise RuntimeError(f"LightRAG initialization failed: {str(e)}")
    
    logger.info("üîß Initializing OpenAI client...")
    openai_client = OpenAI(api_key=OPENAI_API_KEY)
    app.state.openai_client = openai_client
    logger.info("‚úÖ OpenAI client initialized.")
    
    logger.info("üéâ Study4Me backend server startup complete!")
    
    try:
        yield
    finally:
        # Shutdown
        logger.info("üõë Initiating graceful shutdown...")
        
        # Signal shutdown to background tasks
        SHUTDOWN_EVENT.set()
        
        # Wait for background tasks to complete (with timeout)
        if BACKGROUND_TASKS:
            logger.info(f"‚è≥ Waiting for {len(BACKGROUND_TASKS)} background tasks to complete...")
            try:
                await asyncio.wait_for(
                    asyncio.gather(*BACKGROUND_TASKS, return_exceptions=True),
                    timeout=5.0  # Reduced timeout
                )
                logger.info("‚úÖ All background tasks completed.")
            except asyncio.TimeoutError:
                logger.warning("‚ö†Ô∏è Background tasks did not complete within 5 seconds, forcing shutdown.")
                # Cancel remaining tasks aggressively
                cancelled_tasks = []
                for task in BACKGROUND_TASKS.copy():  # Use copy to avoid modification during iteration
                    if not task.done():
                        task.cancel()
                        cancelled_tasks.append(task)
                
                # Wait a bit for cancellations to take effect
                if cancelled_tasks:
                    logger.info(f"üö´ Cancelled {len(cancelled_tasks)} background tasks")
                    try:
                        await asyncio.wait_for(
                            asyncio.gather(*cancelled_tasks, return_exceptions=True),
                            timeout=2.0
                        )
                    except asyncio.TimeoutError:
                        logger.warning("‚ö†Ô∏è Some tasks still didn't respond to cancellation")
                
                # Clear the set
                BACKGROUND_TASKS.clear()
        
        # Finalize LightRAG
        if rag:
            try:
                logger.info("üß† Finalizing LightRAG...")
                await rag.finalize_storages()
                logger.info("‚úÖ LightRAG finalized successfully.")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Error finalizing LightRAG: {str(e)}")
        
        logger.info("‚úÖ Graceful shutdown complete.")

app = FastAPI(title="Study4Me RAG Server", lifespan=lifespan)

# === CORS ===
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# === Dependency to access RAG instance ===
def get_rag(request: Request) -> LightRAG:
    return request.app.state.rag

def get_openai_client(request: Request) -> OpenAI:
    return request.app.state.openai_client

# === Routes ===

@app.get("/", tags=["Debug"])
def root():
    """Basic health check route."""
    return {"message": "Study4Me FastAPI + Docling + LightRAG is running."}

@app.get("/readyz", tags=["Debug"])
def readiness():
    """Kubernetes readiness probe endpoint."""
    return {"status": "ready", "message": "Service is ready to accept requests"}

@app.post("/documents/upload", tags=["Knowledge Upload"])
async def upload_documents(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...),
    study_topic_id: str = Form(..., description="UUID of the study topic this content belongs to"),
    callback_url: Optional[str] = Form(None),
    rag: LightRAG = Depends(get_rag),
):
    # Log upload initiation
    logger.info(f"üìÅ [upload] Starting document upload for study topic: {study_topic_id[:8]}")
    logger.info(f"üìÑ [upload] Number of files: {len(files)}")
    
    # Validate study topic exists
    study_topic = await get_study_topic(study_topic_id)
    if not study_topic:
        logger.warning(f"‚ùå [upload] Study topic not found: {study_topic_id}")
        raise HTTPException(status_code=404, detail=f"Study topic with ID '{study_topic_id}' not found")
    
    logger.info(f"‚úÖ [upload] Study topic validated: '{study_topic['name']}'")
    
    saved_paths = []
    content_items = []
    
    for file in files:
        ext = os.path.splitext(file.filename)[1].lower()
        if ext not in {".pdf", ".docx", ".xls", ".xlsx"}:
            raise HTTPException(status_code=400, detail=f"File type {ext} not supported.")
        
        # Save file
        file_path = os.path.join(UPLOAD_DIR, file.filename)
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        saved_paths.append((file.filename, file_path))
        
        # Create content item record (content will be populated after processing)
        content_id = str(uuid.uuid4())
        content_items.append({
            "content_id": content_id,
            "filename": file.filename,
            "file_path": file_path
        })
        
        logger.info(f"üìÑ [upload] File saved: {file.filename} (ID: {content_id[:8]})")

    # Run in background
    task_id = str(uuid.uuid4())
    with TASK_LOCK:
        TASK_STATUS[task_id] = "processing"
    
    async def process_with_tracking():
        try:
            logger.info(f"‚öôÔ∏è [upload-{task_id[:8]}] Starting document processing...")
            await process_uploaded_documents(saved_paths, rag, callback_url, study_topic_id, content_items)
            with TASK_LOCK:
                TASK_STATUS[task_id] = "done"
            logger.info(f"‚úÖ [upload-{task_id[:8]}] Document processing completed successfully")
        except Exception as e:
            with TASK_LOCK:
                TASK_STATUS[task_id] = "failed"
            logger.error(f"üí• [upload-{task_id[:8]}] Background task failed: {e}")
    
    # Create and track the background task
    task = asyncio.create_task(process_with_tracking())
    BACKGROUND_TASKS.add(task)
    
    # Add cleanup when task completes
    def cleanup_task(finished_task):
        BACKGROUND_TASKS.discard(finished_task)
    
    task.add_done_callback(cleanup_task)

    logger.info(f"üì§ [upload] Upload queued successfully - Task ID: {task_id}")
    return {
        "status": "processing", 
        "files": [name for name, _ in saved_paths], 
        "task_id": task_id,
        "study_topic_id": study_topic_id,
        "study_topic_name": study_topic['name']
    }

@app.get("/datasources", tags=["Datasource Management"])
async def list_datasources():
    """List all uploaded documents with metadata."""
    try:
        if not os.path.exists(UPLOAD_DIR):
            return {"datasources": []}
        
        datasources = []
        for filename in os.listdir(UPLOAD_DIR):
            file_path = os.path.join(UPLOAD_DIR, filename)
            if os.path.isfile(file_path):
                stat_info = os.stat(file_path)
                file_info = {
                    "filename": filename,
                    "size_bytes": stat_info.st_size,
                    "size_mb": round(stat_info.st_size / (1024 * 1024), 2),
                    "upload_time": stat_info.st_mtime,
                    "file_extension": os.path.splitext(filename)[1].lower(),
                    "path": file_path
                }
                datasources.append(file_info)
        
        # Sort by upload time (newest first)
        datasources.sort(key=lambda x: x["upload_time"], reverse=True)
        
        return {
            "total_count": len(datasources),
            "datasources": datasources
        }
    except Exception as e:
        logger.error(f"Error listing datasources: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to list datasources: {e}")

@app.get("/datasources/{filename}/info", tags=["Datasource Management"])
async def get_datasource_info(filename: str):
    """Get detailed metadata about a specific uploaded document."""
    file_path = os.path.join(UPLOAD_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"Datasource '{filename}' not found.")
    
    try:
        stat_info = os.stat(file_path)
        file_info = {
            "filename": filename,
            "size_bytes": stat_info.st_size,
            "size_mb": round(stat_info.st_size / (1024 * 1024), 2),
            "upload_time": stat_info.st_mtime,
            "last_modified": stat_info.st_mtime,
            "file_extension": os.path.splitext(filename)[1].lower(),
            "absolute_path": os.path.abspath(file_path)
        }
        return file_info
    except Exception as e:
        logger.error(f"Error getting datasource info for {filename}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get datasource info: {e}")

@app.get("/datasources/{filename}/download", tags=["Datasource Management"])
async def download_datasource(filename: str):
    """Download a specific uploaded document."""
    file_path = os.path.join(UPLOAD_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"Datasource '{filename}' not found.")
    
    try:
        # Determine media type based on file extension
        ext = os.path.splitext(filename)[1].lower()
        media_type_map = {
            ".pdf": "application/pdf",
            ".docx": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            ".doc": "application/msword",
            ".xls": "application/vnd.ms-excel",
            ".xlsx": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            ".txt": "text/plain",
            ".png": "image/png",
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg"
        }
        media_type = media_type_map.get(ext, "application/octet-stream")
        
        return FileResponse(
            path=file_path,
            media_type=media_type,
            filename=filename
        )
    except Exception as e:
        logger.error(f"Error downloading datasource {filename}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to download datasource: {e}")

@app.delete("/datasources/{filename}", tags=["Datasource Management"])
async def delete_datasource(filename: str):
    """Delete a specific uploaded document from storage."""
    file_path = os.path.join(UPLOAD_DIR, filename)
    
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"Datasource '{filename}' not found.")
    
    try:
        os.remove(file_path)
        logger.info(f"Deleted datasource: {filename}")
        return {
            "message": f"Datasource '{filename}' has been successfully deleted.",
            "filename": filename,
            "status": "deleted"
        }
    except Exception as e:
        logger.error(f"Error deleting datasource {filename}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to delete datasource: {e}")

@app.post("/webpage/process", tags=["Knowledge Upload"])
async def process_webpage(
    background_tasks: BackgroundTasks,
    url: str = Body(..., embed=True),
    study_topic_id: str = Body(..., description="UUID of the study topic this content belongs to", embed=True),
    callback_url: Optional[str] = Body(None, embed=True),
    rag: LightRAG = Depends(get_rag),
):
    # Log webpage processing initiation
    logger.info(f"üåê [webpage] Starting webpage processing for study topic: {study_topic_id[:8]}")
    logger.info(f"üîó [webpage] URL: {url}")
    
    # Validate study topic exists
    study_topic = await get_study_topic(study_topic_id)
    if not study_topic:
        logger.warning(f"‚ùå [webpage] Study topic not found: {study_topic_id}")
        raise HTTPException(status_code=404, detail=f"Study topic with ID '{study_topic_id}' not found")
    
    logger.info(f"‚úÖ [webpage] Study topic validated: '{study_topic['name']}'")
    
    # Create content item record
    content_id = str(uuid.uuid4())
    logger.info(f"üåê [webpage] Content item created (ID: {content_id[:8]})")
    
    # Run in background
    task_id = str(uuid.uuid4())
    with TASK_LOCK:
        TASK_STATUS[task_id] = "processing"
    
    async def process_with_tracking():
        try:
            logger.info(f"‚öôÔ∏è [webpage-{task_id[:8]}] Starting background processing...")
            await process_webpage_background(url, rag, callback_url, study_topic_id, content_id)
            with TASK_LOCK:
                TASK_STATUS[task_id] = "done"
            logger.info(f"‚úÖ [webpage-{task_id[:8]}] Background processing completed successfully")
        except Exception as e:
            with TASK_LOCK:
                TASK_STATUS[task_id] = "failed"
            logger.error(f"üí• [webpage-{task_id[:8]}] Background task failed: {e}")
    
    # Create and track the background task
    task = asyncio.create_task(process_with_tracking())
    BACKGROUND_TASKS.add(task)
    
    # Add cleanup when task completes
    def cleanup_task(finished_task):
        BACKGROUND_TASKS.discard(finished_task)
    
    task.add_done_callback(cleanup_task)
    
    logger.info(f"üì§ [webpage] Webpage processing queued successfully - Task ID: {task_id}")
    return {
        "status": "processing", 
        "url": url, 
        "task_id": task_id,
        "study_topic_id": study_topic_id,
        "study_topic_name": study_topic['name'],
        "content_id": content_id
    }

@app.post("/youtube/process", tags=["Knowledge Upload"])
async def process_youtube_video(
    background_tasks: BackgroundTasks,
    url: str = Form(...),
    study_topic_id: str = Form(..., description="UUID of the study topic this content belongs to"),
    callback_url: Optional[str] = Form(None),
    rag: LightRAG = Depends(get_rag),
):
    """Process YouTube video transcript and add to LightRAG knowledge base"""
    # Log YouTube processing initiation
    logger.info(f"üì∫ [youtube] Starting YouTube processing for study topic: {study_topic_id[:8]}")
    logger.info(f"üîó [youtube] URL: {url}")
    
    # Validate study topic exists
    study_topic = await get_study_topic(study_topic_id)
    if not study_topic:
        logger.warning(f"‚ùå [youtube] Study topic not found: {study_topic_id}")
        raise HTTPException(status_code=404, detail=f"Study topic with ID '{study_topic_id}' not found")
    
    logger.info(f"‚úÖ [youtube] Study topic validated: '{study_topic['name']}'")
    
    # Create content item record
    content_id = str(uuid.uuid4())
    logger.info(f"üì∫ [youtube] Content item created (ID: {content_id[:8]})")
    
    task_id = str(uuid.uuid4())
    with TASK_LOCK:
        TASK_STATUS[task_id] = "processing"

    async def process_with_tracking():
        try:
            logger.info(f"‚öôÔ∏è [youtube-{task_id[:8]}] Starting background processing...")
            start_bg = time.perf_counter()
            
            await process_youtube_background(url, rag, task_id, callback_url, study_topic_id, content_id)
            
            total_bg = time.perf_counter() - start_bg
            logger.info(f"‚úÖ [youtube-{task_id[:8]}] Background processing completed in {total_bg:.2f}s")
            
            with TASK_LOCK:
                TASK_STATUS[task_id] = "done"
        except Exception as e:
            total_bg = time.perf_counter() - start_bg if 'start_bg' in locals() else 0
            logger.error(f"üí• [youtube-{task_id[:8]}] Background processing failed after {total_bg:.2f}s: {str(e)}")
            logger.error(f"üîç [youtube-{task_id[:8]}] Error details: {type(e).__name__}: {str(e)}")
            
            with TASK_LOCK:
                TASK_STATUS[task_id] = "failed"
    
    # Create and track the background task
    task = asyncio.create_task(process_with_tracking())
    BACKGROUND_TASKS.add(task)
    
    # Add cleanup when task completes
    def cleanup_task(finished_task):
        BACKGROUND_TASKS.discard(finished_task)
    
    task.add_done_callback(cleanup_task)
    
    logger.info(f"üì§ [youtube-{task_id[:8]}] YouTube processing queued successfully")
    return {
        "status": "processing", 
        "task_id": task_id, 
        "url": url,
        "study_topic_id": study_topic_id,
        "study_topic_name": study_topic['name'],
        "content_id": content_id,
        "message": "YouTube video processing started. Transcript will be extracted and added to knowledge base."
    }

@app.get("/youtube/transcript", tags=["YouTube"])
async def get_transcript(
    url: str = Query(..., description="YouTube video URL"),
    lang: Optional[str] = Query("en", description="Language code (e.g., 'en', 'es', 'pt')")
):
    """Get transcript for a single YouTube video"""
    return await get_youtube_transcript(url, lang)

@app.post("/youtube/batch", tags=["YouTube"])
async def batch_transcripts(request: BatchRequest):
    """Process multiple YouTube videos and return their transcripts"""
    return await batch_youtube_transcripts(request)

@app.get("/query", tags=["Queries"])
async def query_rag(
    query: str = Query(...),
    mode: Optional[str] = Query("hybrid"),
    rag: LightRAG = Depends(get_rag)
):
    """Query the LightRAG system using different RAG modes."""
    query_id = str(uuid.uuid4())[:8]  # Short ID for tracking
    start_total = time.perf_counter()
    
    # Log query start with details
    logger.info(f"üîç [query-{query_id}] Starting synchronous query")
    logger.info(f"üìù [query-{query_id}] Mode: {mode} | Query length: {len(query)} chars")
    logger.debug(f"üìÑ [query-{query_id}] Query content: {query[:200]}{'...' if len(query) > 200 else ''}")
    
    try:
        # Log LightRAG processing start
        t0 = time.perf_counter()
        logger.info(f"‚öôÔ∏è [query-{query_id}] Starting LightRAG processing...")
        
        param = QueryParam(mode=mode)
        result = await asyncio.to_thread(rag.query, query, param=param)
        
        t1 = time.perf_counter()
        rag_time = t1 - t0
        logger.info(f"‚úÖ [query-{query_id}] LightRAG processing completed: {rag_time:.2f}s")

        # Calculate total time and log results
        total = time.perf_counter() - start_total
        result_length = len(str(result)) if result else 0
        
        logger.info(f"üéâ [query-{query_id}] Query completed successfully:")
        logger.info(f"   ‚è±Ô∏è  Total time: {total:.2f}s")
        logger.info(f"   üß† LightRAG time: {rag_time:.2f}s ({(rag_time/total)*100:.1f}%)")
        logger.info(f"   üìä Response length: {result_length} chars")
        logger.info(f"   üîß Mode used: {mode}")

        return {"result": result}
        
    except (AuthenticationError, RateLimitError, APIError) as e:
        logger.error(f"‚ùå [query-{query_id}] OpenAI API error after {time.perf_counter() - start_total:.2f}s")
        raise handle_openai_error(e)
    except Exception as e:
        total_time = time.perf_counter() - start_total
        logger.error(f"üí• [query-{query_id}] Query failed after {total_time:.2f}s: {str(e)}")
        logger.error(f"üîç [query-{query_id}] Error details: {type(e).__name__}: {str(e)}")
        return JSONResponse(status_code=500, content={
            "error": "Query processing failed",
            "message": str(e),
            "type": "processing_error",
            "query_id": query_id,
            "processing_time": round(total_time, 2)
        })

@app.post("/query-async", tags=["Queries"])
async def query_rag_async(
    background_tasks: BackgroundTasks,
    query: str = Query(...),
    mode: Optional[str] = Query("hybrid"),
    callback_url: Optional[str] = Form(None),
    rag: LightRAG = Depends(get_rag),
):
    task_id = str(uuid.uuid4())
    
    # Log async query initiation
    logger.info(f"üöÄ [async-{task_id[:8]}] Initiating async query")
    logger.info(f"üìù [async-{task_id[:8]}] Mode: {mode} | Query length: {len(query)} chars")
    logger.info(f"üîó [async-{task_id[:8]}] Callback URL: {'Yes' if callback_url else 'No'}")
    logger.debug(f"üìÑ [async-{task_id[:8]}] Query content: {query[:200]}{'...' if len(query) > 200 else ''}")

    with TASK_LOCK:
        TASK_STATUS[task_id] = "processing"

    async def process_with_tracking():
        try:
            logger.info(f"‚öôÔ∏è [async-{task_id[:8]}] Starting background processing...")
            start_bg = time.perf_counter()
            
            await process_query_background(query, mode, rag, task_id, callback_url)
            
            total_bg = time.perf_counter() - start_bg
            logger.info(f"‚úÖ [async-{task_id[:8]}] Background processing completed in {total_bg:.2f}s")
            
            with TASK_LOCK:
                TASK_STATUS[task_id] = "done"
        except Exception as e:
            total_bg = time.perf_counter() - start_bg if 'start_bg' in locals() else 0
            logger.error(f"üí• [async-{task_id[:8]}] Background query failed after {total_bg:.2f}s: {str(e)}")
            logger.error(f"üîç [async-{task_id[:8]}] Error details: {type(e).__name__}: {str(e)}")
            
            with TASK_LOCK:
                TASK_STATUS[task_id] = "failed"
    
    # Create and track the background task
    task = asyncio.create_task(process_with_tracking())
    BACKGROUND_TASKS.add(task)
    
    # Add cleanup when task completes
    def cleanup_task(finished_task):
        BACKGROUND_TASKS.discard(finished_task)
    
    task.add_done_callback(cleanup_task)
    
    logger.info(f"üì§ [async-{task_id[:8]}] Async query queued successfully")
    return {
        "status": "processing", 
        "task_id": task_id, 
        "query_preview": query[:100] + "..." if len(query) > 100 else query,
        "mode": mode
    }

@app.get("/graph/json", tags=["Knowledge Graph"])
async def get_knowledge_graph_from_file():
    """Load the knowledge graph from GraphML and return it as JSON."""
    if not os.path.exists(GRAPHML_PATH):
        raise HTTPException(status_code=404, detail="GraphML file not found.")
    try:
        G = nx.read_graphml(GRAPHML_PATH)
        nodes = [{"id": str(n), **G.nodes[n]} for n in G.nodes]
        edges = [{"source": str(u), "target": str(v), **d} for u, v, d in G.edges(data=True)]
        return {"nodes": nodes, "edges": edges}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load graph: {e}")

@app.get("/graph/graphml", tags=["Knowledge Graph"])
async def download_graphml():
    """Download the knowledge graph file in GraphML format."""
    if not os.path.exists(GRAPHML_PATH):
        raise HTTPException(status_code=404, detail="GraphML file not found.")
    return FileResponse(
        path=GRAPHML_PATH,
        media_type="application/xml",
        filename=os.path.basename(GRAPHML_PATH)
    )

@app.get("/graph/png", tags=["Knowledge Graph"])
async def download_graph_png():
    """Render the knowledge graph as a PNG image and return it in-memory."""
    if not os.path.exists(GRAPHML_PATH):
        raise HTTPException(status_code=404, detail="GraphML file not found.")
    try:
        G = nx.read_graphml(GRAPHML_PATH)
        plt.figure(figsize=(20, 12))
        pos = nx.spring_layout(G, k=0.5)
        nx.draw(
            G, pos,
            with_labels=True,
            node_size=500,
            node_color="skyblue",
            font_size=8,
            edge_color="gray",
            arrows=True
        )
        buffer = io.BytesIO()
        plt.tight_layout()
        plt.savefig(buffer, format="png")
        plt.close()
        buffer.seek(0)
        return StreamingResponse(buffer, media_type="image/png", headers={
            "Content-Disposition": "inline; filename=knowledge_graph.png"
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to render PNG: {e}")

@app.post("/image/interpret", tags=["Knowledge Upload"])
async def interpret_image(
    background_tasks: BackgroundTasks,
    image: UploadFile = File(...),
    study_topic_id: str = Form(..., description="UUID of the study topic this content belongs to"),
    prompt: Optional[str] = Body("Describe this image and extract key information", embed=True),
    callback_url: Optional[str] = Form(None),
    openai_client: OpenAI = Depends(get_openai_client),
    rag: LightRAG = Depends(get_rag)
):
    # Log image processing initiation
    logger.info(f"üñºÔ∏è [image] Starting image processing for study topic: {study_topic_id[:8]}")
    logger.info(f"üìÑ [image] Filename: {image.filename}")
    
    # Validate study topic exists
    study_topic = await get_study_topic(study_topic_id)
    if not study_topic:
        logger.warning(f"‚ùå [image] Study topic not found: {study_topic_id}")
        raise HTTPException(status_code=404, detail=f"Study topic with ID '{study_topic_id}' not found")
    
    logger.info(f"‚úÖ [image] Study topic validated: '{study_topic['name']}'")
    
    # Create content item record
    content_id = str(uuid.uuid4())
    logger.info(f"üñºÔ∏è [image] Content item created (ID: {content_id[:8]})")
    
    # Save file for later processing
    file_path = os.path.join(UPLOAD_DIR, image.filename)
    with open(file_path, "wb") as f:
        f.write(await image.read())

    # Run in background
    task_id = str(uuid.uuid4())
    with TASK_LOCK:
        TASK_STATUS[task_id] = "processing"
    
    async def process_with_tracking():
        try:
            await process_image_background(file_path, prompt, image.filename, openai_client, rag, callback_url, study_topic_id, content_id)
            with TASK_LOCK:
                TASK_STATUS[task_id] = "done"
        except Exception as e:
            with TASK_LOCK:
                TASK_STATUS[task_id] = "failed"
            logger.error(f"[{task_id}] Background task failed: {e}")
    
    # Create and track the background task
    task = asyncio.create_task(process_with_tracking())
    BACKGROUND_TASKS.add(task)
    
    # Add cleanup when task completes
    def cleanup_task(finished_task):
        BACKGROUND_TASKS.discard(finished_task)
    
    task.add_done_callback(cleanup_task)

    logger.info(f"üì§ [image] Image processing queued successfully - Task ID: {task_id}")
    return {
        "status": "processing", 
        "filename": image.filename, 
        "task_id": task_id,
        "study_topic_id": study_topic_id,
        "study_topic_name": study_topic['name'],
        "content_id": content_id
    }
    
@app.get("/task-status/{task_id}", tags=["Tasks"])
async def get_task_status_combined(task_id: str):
    with TASK_LOCK:
        status = TASK_STATUS.get(task_id)

    if status is None:
        raise HTTPException(status_code=404, detail="Task ID not found")

    # Fetch result from database if available
    result = await fetch_task_result(task_id)

    return {
        "task_id": task_id,
        "status": status,
        "result": result["result"] if result and status == "done" else None,
        "processing_time_seconds": result["processing_time"] if result and status == "done" else None
    }

# === Study Topics Management ===

@app.post("/study-topics", tags=["Study Topics"], response_model=dict)
async def create_new_study_topic(topic: StudyTopicCreate):
    """Create a new study topic and return its UUID"""
    try:
        # Generate UUID for the topic
        topic_id = str(uuid.uuid4())
        
        # Log topic creation
        logger.info(f"üìö Creating new study topic: '{topic.name}' (ID: {topic_id[:8]})")
        logger.info(f"üìù Description: {topic.description[:100] + '...' if topic.description and len(topic.description) > 100 else topic.description or 'None'}")
        logger.info(f"üß† Knowledge graph enabled: {topic.use_knowledge_graph}")
        
        # Save to database
        await create_study_topic(
            topic_id=topic_id,
            name=topic.name,
            description=topic.description,
            use_knowledge_graph=topic.use_knowledge_graph
        )
        
        logger.info(f"‚úÖ Study topic created successfully: {topic_id}")
        
        return {
            "message": "Study topic created successfully",
            "topic_id": topic_id,
            "name": topic.name,
            "description": topic.description,
            "use_knowledge_graph": topic.use_knowledge_graph
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error creating study topic: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to create study topic: {str(e)}")

@app.get("/study-topics", tags=["Study Topics"], response_model=dict)
async def get_study_topics(
    limit: int = Query(100, ge=1, le=1000, description="Maximum number of topics to return"),
    offset: int = Query(0, ge=0, description="Number of topics to skip")
):
    """List all study topics with pagination"""
    try:
        logger.info(f"üìö Fetching study topics (limit: {limit}, offset: {offset})")
        
        topics = await list_study_topics(limit=limit, offset=offset)
        
        logger.info(f"‚úÖ Retrieved {len(topics)} study topics")
        
        return {
            "total_retrieved": len(topics),
            "limit": limit,
            "offset": offset,
            "topics": topics
        }
        
    except Exception as e:
        logger.error(f"‚ùå Error fetching study topics: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch study topics: {str(e)}")

@app.get("/study-topics/{topic_id}", tags=["Study Topics"], response_model=StudyTopicResponse)
async def get_study_topic_by_id(topic_id: str):
    """Get a specific study topic by its UUID"""
    try:
        logger.info(f"üìö Fetching study topic: {topic_id}")
        
        topic = await get_study_topic(topic_id)
        
        if not topic:
            logger.warning(f"‚ùå Study topic not found: {topic_id}")
            raise HTTPException(status_code=404, detail=f"Study topic with ID '{topic_id}' not found")
        
        logger.info(f"‚úÖ Retrieved study topic: {topic['name']}")
        
        return topic
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error fetching study topic {topic_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to fetch study topic: {str(e)}")

@app.put("/study-topics/{topic_id}", tags=["Study Topics"], response_model=dict)
async def update_study_topic_by_id(topic_id: str, topic_update: StudyTopicUpdate):
    """Update an existing study topic"""
    try:
        logger.info(f"üìö Updating study topic: {topic_id}")
        
        # Check if topic exists
        existing_topic = await get_study_topic(topic_id)
        if not existing_topic:
            logger.warning(f"‚ùå Study topic not found for update: {topic_id}")
            raise HTTPException(status_code=404, detail=f"Study topic with ID '{topic_id}' not found")
        
        # Update the topic
        updated = await update_study_topic(
            topic_id=topic_id,
            name=topic_update.name,
            description=topic_update.description,
            use_knowledge_graph=topic_update.use_knowledge_graph
        )
        
        if not updated:
            logger.warning(f"‚ö†Ô∏è No changes made to study topic: {topic_id}")
            return {"message": "No changes made to study topic", "topic_id": topic_id}
        
        # Fetch updated topic
        updated_topic = await get_study_topic(topic_id)
        
        logger.info(f"‚úÖ Study topic updated successfully: {topic_id}")
        
        return {
            "message": "Study topic updated successfully",
            "topic": updated_topic
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error updating study topic {topic_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to update study topic: {str(e)}")

@app.delete("/study-topics/{topic_id}", tags=["Study Topics"], response_model=dict)
async def delete_study_topic_by_id(topic_id: str):
    """Delete a study topic"""
    try:
        logger.info(f"üìö Deleting study topic: {topic_id}")
        
        # Check if topic exists
        existing_topic = await get_study_topic(topic_id)
        if not existing_topic:
            logger.warning(f"‚ùå Study topic not found for deletion: {topic_id}")
            raise HTTPException(status_code=404, detail=f"Study topic with ID '{topic_id}' not found")
        
        # Delete the topic
        deleted = await delete_study_topic(topic_id)
        
        if not deleted:
            logger.error(f"‚ùå Failed to delete study topic: {topic_id}")
            raise HTTPException(status_code=500, detail="Failed to delete study topic")
        
        logger.info(f"‚úÖ Study topic deleted successfully: {existing_topic['name']} ({topic_id})")
        
        return {
            "message": "Study topic deleted successfully",
            "topic_id": topic_id,
            "name": existing_topic["name"]
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error deleting study topic {topic_id}: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Failed to delete study topic: {str(e)}")